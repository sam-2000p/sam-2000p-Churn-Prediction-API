import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import joblib

# Load the dataset
df = pd.read_csv("Churn_Modelling.csv")

# ðŸ”¹ Show first 5 rows
print("ðŸ”¹ First 5 rows of the dataset:")
print(df.head(), "\n")

# ðŸ”¹ Check for missing values
print("ðŸ”¹ Missing values in each column:")
print(df.isnull().sum(), "\n")

# ðŸ”¹ Dataset info
print("ðŸ”¹ Dataset Info:")
print(df.info(), "\n")

# ðŸ”¹ Statistical summary
print("ðŸ”¹ Statistical Summary:")
print(df.describe(), "\n")

# Drop unnecessary column (only if it exists)
df = df.drop(['customer_id'], axis=1)
print(f"ðŸ”¹ Columns after dropping irrelevant ones:\n{df.columns}\n")

# ðŸ”¹ Label Encoding for 'gender' (binary: Male/Female)
label_encoder = LabelEncoder()
df['gender'] = label_encoder.fit_transform(df['gender'])

# ðŸ”¹ One-Hot Encoding for 'country' (nominal with multiple categories)
df = pd.get_dummies(df, columns=['country'], drop_first=True)

# ðŸ”¹ Define Features (X) and Target (y)
X = df.drop('churn', axis=1)  # All columns except 'churn'
y = df['churn']  # Target column

# ðŸ”¹ Split the data into training and testing sets (80% train, 20% test)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ðŸ”¹ Feature Scaling (Standardizing the features)
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# ðŸ”¹ Train a Logistic Regression model
model = LogisticRegression(random_state=42)
model.fit(X_train, y_train)

# ðŸ”¹ Hyperparameter tuning for Logistic Regression
param_grid = {
    'C': [0.01, 0.1, 1, 10],
    'solver': ['liblinear', 'saga']
}
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)
grid_search.fit(X_train, y_train)
print("ðŸ”¹ Best Hyperparameters (Logistic Regression):", grid_search.best_params_)

# ðŸ”¹ Get the best model and evaluate it
best_logreg_model = grid_search.best_estimator_
y_pred_logreg = best_logreg_model.predict(X_test)

# ðŸ”¹ Evaluate Logistic Regression model
print("ðŸ”¹ Accuracy on Test Data (Logistic Regression):", accuracy_score(y_test, y_pred_logreg))
print("\nðŸ”¹ Classification Report (Logistic Regression):\n", classification_report(y_test, y_pred_logreg))
print("\nðŸ”¹ Confusion Matrix (Logistic Regression):")
cm_logreg = confusion_matrix(y_test, y_pred_logreg)

# ðŸ”¹ Visualize the confusion matrix (Logistic Regression)
sns.heatmap(cm_logreg, annot=True, fmt='d', cmap='Blues', xticklabels=["No Churn", "Churn"], yticklabels=["No Churn", "Churn"])
plt.title("Confusion Matrix (Logistic Regression)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ðŸ”¹ Cross-validation for Logistic Regression
cv_scores_logreg = cross_val_score(best_logreg_model, X_train, y_train, cv=5, scoring='accuracy')
print("ðŸ”¹ Cross-validation Scores (Logistic Regression):", cv_scores_logreg)
print("ðŸ”¹ Mean Cross-validation Score (Logistic Regression):", cv_scores_logreg.mean())

# ðŸ”¹ Train Random Forest model (for comparison)
rf_model = RandomForestClassifier(random_state=42)
rf_model.fit(X_train, y_train)

# ðŸ”¹ Predict and evaluate Random Forest model
rf_y_pred = rf_model.predict(X_test)
print("ðŸ”¹ Accuracy on Test Data (Random Forest):", accuracy_score(y_test, rf_y_pred))
print("\nðŸ”¹ Classification Report (Random Forest):\n", classification_report(y_test, rf_y_pred))
print("\nðŸ”¹ Confusion Matrix (Random Forest):")
cm_rf = confusion_matrix(y_test, rf_y_pred)

# ðŸ”¹ Visualize the confusion matrix (Random Forest)
sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Blues', xticklabels=["No Churn", "Churn"], yticklabels=["No Churn", "Churn"])
plt.title("Confusion Matrix (Random Forest)")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

# ðŸ”¹ Cross-validation for Random Forest
cv_scores_rf = cross_val_score(rf_model, X_train, y_train, cv=5, scoring='accuracy')
print("ðŸ”¹ Cross-validation Scores (Random Forest):", cv_scores_rf)
print("ðŸ”¹ Mean Cross-validation Score (Random Forest):", cv_scores_rf.mean())

# ðŸ”¹ Save the best model (Logistic Regression) or Random Forest model
joblib.dump(best_logreg_model, "churn_logreg_model.pkl")
# or save the random forest model:
# joblib.dump(rf_model, "churn_rf_model.pkl")
